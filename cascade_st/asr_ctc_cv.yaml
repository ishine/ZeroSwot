# @package _global_

hydra:
  run:
    dir: ${env:SAVE_DIR}/${env:WANDB_NAME}/hydra_outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}

common:
  log_interval: 50
  log_format: json
  seed: 42
  fp16: True
  empty_cache_freq: 500
  wandb_project: ${env:WANDB_PROJECT}
  user_dir: ${env:FAIRSEQ_ROOT}/examples/extended_siamese

dataset:
  train_subset: train_siamese
  valid_subset: dev_siamese
  num_workers: 2
  max_tokens: 1_600_000
  max_tokens_valid: 3_000_000
  validate_interval: 500
  skip_invalid_size_inputs_valid_test: True
  required_batch_size_multiple: 1

optimization:
  lr: [1e-4]
  update_freq: [20]
  skip_remainder_batch: True
  max_update: 100_000
  clip_norm: 1.0

checkpoint:
  # no_save: True
  save_dir: ${env:SAVE_DIR}/asr_models/${env:WANDB_NAME}/ckpts/
  keep_best_checkpoints: 10
  no_epoch_checkpoints: True
  no_absolute_best_checkpoints: True
  no_interval_updates_checkpoints: True
  no_last_checkpoints: True
  save_interval: 999_999
  save_interval_updates: 500
  best_checkpoint_metric: loss
  early_stop_metric: loss
  patience: 10

model:
  _name: siamese_encoders_with_ctc
  speech_encoder:
    path: ${env:MODELS_ROOT}/wav2vec2/wav2vec_vox_960h_pl.pt
    dropout: 0.0
    attention_dropout: 0.0
    activation_dropout: 0.1
    layerdrop: 0.0
    final_dropout: 0.1
    dropout_input: 0.0
    apply_mask: True
    mask_length: 10
    mask_prob: 0.5
    mask_channel_length: 64
    mask_channel_prob: 0.25
  text_encoder:
    path: ${env:MODELS_ROOT}/nllb/nllb-200-distilled-600M.pt
    remove: True
  ctc_decoder:
    dictionary_path: ${env:MODELS_ROOT}/wav2vec2/dict.ltr.txt
    dropout: 0.1

task:
  _name: siamese_speech_text
  data: ${env:DATA_ROOT}/siamese/CommonVoice
  config_yaml: ${env:ZS_ROOT}/zs_st/data_config.yaml
  max_source_positions: 400_000
  max_target_positions: 1024
  max_positions_text: 512

criterion:
  _name: ctc_wass
  ctc_weight: 1.0
  zero_infinity: True
  ot_weight: 0.0
  ot_pos_weight: 1.0

optimizer:
  _name: adam
  adam_betas: (0.9, 0.98)
  adam_eps: 1e-08

lr_scheduler:
  _name: inverse_sqrt
  warmup_updates: 2_000